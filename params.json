{"name":"DynamicData","tagline":"Persistent Multithreaded Array like Data Structure","body":"### Introduction\r\n\r\nDynamic Data (DD) is a reference implementation for a persistent on disc Concurrent Mapped Vector CMV. Please read on further down for a definition of a CMV data structure. The DD data structure is useful in situations where a big number of objects has to be stored in an array like data structure and fast random read access is needed, as well as frequent insert and delete operations with minimal lock time. \r\nUsually B-trees or Skip Lists are employed in these kind of situations, with the disadvantage that random reads have a complexity of O(log(n)), where the DD data structure can achieve O(0) complexity on random reads in many situations where reads are much more frequent then delete and write operations.\r\n\r\nSetup\r\n\r\nDD is a header file only library which was developed on OSX and Xcode. The code is standard C++11 compatible, the only non stl component used is <sys/mman.h>, which is used to mmap binary files on disc. We suppose that the library should run on most Unix systems, but it was only tested on OSX. \r\n\r\nFor basic usage of the library have a look at Demo.h. The only important class for user code is DDIndex. This class manages the array and keeps it persistent on disc. The persistent data will be stored relatively to the executable in a folder called data. On succedent startups the different ids passed to the constructor of DDIndex will identify the data files or create new ones if they do not exist. Its probably wise to remove all the data in the data folder if data has to be removed manually or data inconsistencies can happen.\r\n\r\nWe believe that this kind of data structure did not exist until now (at least we could not find any similar work at all). Thats why we gave it the name Concurrent Mapped Vector. It might not be the most pretty name, but it should reflect that what we have is an array like data structure which can only work effectively in a multithreaded environment. \r\n\r\n### Concurrent Mapped Vector\r\n\r\nIntroduction\r\n\r\nThe Concurrent Mapped Vector (CMV) is a data structure, which exposes a similar subset of operations found in vector classes like in the std::vector class. \r\n\r\nThis is the interface CMV exposes:\r\n\r\n```\r\ny_type get(size_type idx) // random access\r\nvoid insertIdx(size_type idx, y_type yvalue) // random insert \r\nvoid deleteIdx(size_type idx) // random delete \r\n```\r\n\r\nHere size_type is an unsigned integral type and y_type is a scalar value or a struct.\r\n\r\nIt is important to mention, that the CMVs indexes can not be used as keys like in a Hash Map. The following example illustrates this.\r\n\r\n```\r\n//pseudocode\r\n//let d be an instantiation of D with int value types. Let d contain 5 elements.\r\n\r\n//insert 6 at index 3\r\nsk.insert(3, 6);\r\n\r\n//insert 5 at index 3\r\nsk.insert(3, 5);\r\n\r\n//get index 4\r\nint value = sk.get(4);\r\n```\r\n\r\nThe return value will be 6, because 5 was inserted at index 3 so the value 6 moved one index up.\r\n\r\nThe question remains why one should bother to implement a simplified vector like data structure like the CMV. The answer lies in the complexity to calculate these operations. The CMV can outperform vector and list like data structures in many situations.\r\n\r\nThe CMV works transactionally and multithreaded. This means that it always accumulates a certain number of operations, these are the pending elements. Other background working threads then incorporate these pending operations into the core memory of the CMV data structure, which can be in RAM or on disc.\r\n\r\nThe complexity for all the operations the CMV exposes, can be described as follows.\r\nLet P_N be the pending elements. Then the complexity for all operations is \r\n\r\n```\r\nO(log(P_N))\r\n```\r\n\r\nThis means that if the background working threads are fast enough to keep P_N small, then the complexity can become constant O(0). \r\n\r\nIn the current implementation the operations needed to incorporate P_N pending elements is\r\n\r\n```\r\nBACKGROUND_OPS = P_N + N \r\n```\r\n\r\nwhere N is the number of elements currently contained in CMVs core memory. We are not sure yet if BACKGROUND_OPS can be even more optimized like in\r\n\r\n```\r\nBACKGROUND_OPS = log(P_N +N)  \r\n```\r\n\r\nBecause of fast multithreaded hardware one can imagine that the frequency operations can occur on CMV can be quite high and still P_N can be kept small and constant.\r\n\r\n\r\nThe Dynamic Data Project (DD)\r\n\r\nThe Dynamic Data Project is a reference implementation for a MVC data structure, where the core memory is kept persistently on disc. Our proposed design allows with relatively simple modifications to have the core memory stored on disc or in the systems RAM. To keep the project simple we decided to only implement the on disc storage behaviour. Our initial thought was also to use  DDP as a simple database rather than an in memory data structure. The DDP is still a prototype and should probably be tested more to be used in production work. There are still many performance improvements which could be implemented. But our main focus in this project was to reduce the BACKGROUND_OPS because this gives the biggest performance boost.\r\nWe have to mention that the complexity for the insert and delete operations is O(log(P_N) + P_N) rather than O(log(P_N)). But this shortcoming could be overcome if we used a special skip list in our implementation. \r\n\r\n\r\nImplementation Overview\r\n\r\nFirst we describe the components used and later how the different operations are implemented using these basic components.\r\n\r\nWe use 2 in memory objects which cache the insert and delete operations. They both accept indexes and transform them based on the already inserted or deleted elements. A backgound process processes these fields and writes the data to disk regularly. The insert field also caches the the inserted value.\r\n\r\n![delete_field](db_obj_del_field.png)\r\n![insert_field](db_obj_insert_field.png)\r\n\r\nFor accessing the elements on disc we use an Index Map Array as well as a Value Array.\r\nThe Index Map Array maps the indexes to the Value Array. When inserting and deleting elements only the mappings can be adjusted and the newly inserted values can be added at the end of the Value Array.\r\n\r\n![index_map_array](db_obj_mapped_arr.png)\r\n![value_map_array](db_obj_val_arr.png)\r\n\r\nThe different Operations \r\n\r\nTo cache the inserted and deleted values, the insert and delete fields will be called in a serial fashion. All inserts and deletes are sorted, in this way the operations necessary to perform for the background thread can be optimised. This is because multiple insert and delete operations on there own can be cached as a list of offset values in the Index Map Array.\r\nFirst the delete values are stored and then the insert values. In order to calculate the index which has to be cached for an insert operation the delete field has to be queried to transform the index.   \r\n\r\n###### Insert Operation\r\n![insert_op](db_insert_op.png)\r\n\r\n###### Delete Operation\r\n![delete_op](db_del_op.png)\r\n\r\nTo access Elements in the data structure all Objects described have to be used. A query for an index idx has to pass the delete field first, to check whether it has to be adjusted. Then it has to pass the insert field which checks if the value for idx is cached. if so the value will be returned, in all other cases the again transformed index is passed to the Index Map Array, where it is again transformed to the index which can access the Value array.\r\nThe complexity for this operation involves two O(log(n)) operations for the index and delete fields and two disc accesses. Thus the Get Operation has an O(log(n)) complexity, where n are the pending elements not yet written to disc by the background process.\r\n\r\n###### Get Operation\r\n![get_op](db_get_op.png)\r\n\r\n\r\n![bg_process](db_bg_job.png)\r\n\r\nThe Background Process (BPRO)\r\n\r\nThe BPRO uses the stored data in the delete and insert fields. The algorithm has to iterate over the Index Map Array and adjust all the indexes, as well as inserting and deleting values in the Value Array. When done it can erase the data in the in the fields and reset them.\r\n\r\nThe BPRO runs concurrently with the three operations described above. In this simplified implementation overview it looks as if the BPRO would have to access the same objects as the operations above. But the basic elements internal structure can be doubled so that the BPRO can access one part of the structure and when finishing the structures can be switched. This describes basically a Copy-on-write (COW) strategy. ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}